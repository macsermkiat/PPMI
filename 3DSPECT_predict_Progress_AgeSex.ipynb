{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "#from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "#from fastai.model import *\n",
    "#from fastai.dataset import *\n",
    "#from fastai.sgdr import *\n",
    "#from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import glob\n",
    "import os\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./\"\n",
    "SPECTPATH = Path(\"../data/PPMISPECT/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for dirName, subdirList, fileList in os.walk(PathDicom):\\n    for filename in fileList:\\n        if \".dcm\" in filename.lower():  # check whether the file\\'s DICOM\\n            lstFilesDCM.append(os.path.join(dirName,filename))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstFilesDCM = []  # create an empty list\n",
    "'''for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "            lstFilesDCM.append(os.path.join(dirName,filename))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(f'{PATH}PPMI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>388628</td>\n",
       "      <td>4140</td>\n",
       "      <td>Control</td>\n",
       "      <td>M</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/09/2013</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>388627</td>\n",
       "      <td>4139</td>\n",
       "      <td>Control</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>3/19/2013</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388626</td>\n",
       "      <td>4137</td>\n",
       "      <td>PD</td>\n",
       "      <td>M</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>4/02/2013</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>388625</td>\n",
       "      <td>4136</td>\n",
       "      <td>PD</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/13/2013</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>451290</td>\n",
       "      <td>4135</td>\n",
       "      <td>PD</td>\n",
       "      <td>M</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/18/2014</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Data ID  Subject    Group Sex  Age  Visit Modality  \\\n",
       "0         388628     4140  Control   M   76      0    SPECT   \n",
       "1         388627     4139  Control   M   81      0    SPECT   \n",
       "2         388626     4137       PD   M   70      0    SPECT   \n",
       "3         388625     4136       PD   M   56      0    SPECT   \n",
       "4         451290     4135       PD   M   68      5    SPECT   \n",
       "\n",
       "             Description       Type   Acq Date Format Downloaded  \n",
       "0  Reconstructed DaTSCAN  Processed  4/09/2013    DCM  5/27/2018  \n",
       "1  Reconstructed DaTSCAN  Processed  3/19/2013    DCM  5/27/2018  \n",
       "2  Reconstructed DaTSCAN  Processed  4/02/2013    DCM  5/27/2018  \n",
       "3  Reconstructed DaTSCAN  Processed  2/13/2013    DCM  5/27/2018  \n",
       "4  Reconstructed DaTSCAN  Processed  2/18/2014    DCM  5/27/2018  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle data\n",
    "metadata = metadata.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360618</td>\n",
       "      <td>3769</td>\n",
       "      <td>Control</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>10/25/2012</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>388617</td>\n",
       "      <td>4122</td>\n",
       "      <td>PD</td>\n",
       "      <td>M</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>2/06/2013</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363956</td>\n",
       "      <td>3870</td>\n",
       "      <td>PD</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>11/29/2012</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>388601</td>\n",
       "      <td>4107</td>\n",
       "      <td>PD</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>12/21/2012</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>419581</td>\n",
       "      <td>3829</td>\n",
       "      <td>PD</td>\n",
       "      <td>F</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>SPECT</td>\n",
       "      <td>Reconstructed DaTSCAN</td>\n",
       "      <td>Processed</td>\n",
       "      <td>10/01/2013</td>\n",
       "      <td>DCM</td>\n",
       "      <td>5/27/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Data ID  Subject    Group Sex  Age  Visit Modality  \\\n",
       "0         360618     3769  Control   M   71      0    SPECT   \n",
       "1         388617     4122       PD   M   64      0    SPECT   \n",
       "2         363956     3870       PD   F   41      0    SPECT   \n",
       "3         388601     4107       PD   M   71      0    SPECT   \n",
       "4         419581     3829       PD   F   68      5    SPECT   \n",
       "\n",
       "             Description       Type    Acq Date Format Downloaded  \n",
       "0  Reconstructed DaTSCAN  Processed  10/25/2012    DCM  5/27/2018  \n",
       "1  Reconstructed DaTSCAN  Processed   2/06/2013    DCM  5/27/2018  \n",
       "2  Reconstructed DaTSCAN  Processed  11/29/2012    DCM  5/27/2018  \n",
       "3  Reconstructed DaTSCAN  Processed  12/21/2012    DCM  5/27/2018  \n",
       "4  Reconstructed DaTSCAN  Processed  10/01/2013    DCM  5/27/2018  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(f'{PATH}PPMI*/**/Reconstructed_DaTSCAN/**/**/*.dcm'):\n",
    "    lstFilesDCM.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstFilesDCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptID = []\n",
    "for i in lstFilesDCM:\n",
    "    j = i.split(\"_\")[13].strip()\n",
    "    j = int(j[1:7])\n",
    "    ptID.append(j)\n",
    "len(ptID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p ={}\n",
    "for o in ptID:\n",
    "    for k in metadata.iloc[:,0]:\n",
    "        if o == k:\n",
    "            p[o] = metadata.loc[metadata['Image Data ID'] == k, 'Group'].tolist()[0]\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = metadata[['Image Data ID','Group','Subject','Age','Sex']].set_index('Image Data ID')\n",
    "for index, rows in df.iterrows():\n",
    "    for i in lstFilesDCM:\n",
    "        j = i.split(\"_\")[13].strip()\n",
    "        j = int(j[1:7])\n",
    "        if index == j:\n",
    "            df.loc[df.index == j, \"Filenames\"] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check duplicate item\n",
    "bg = []\n",
    "for i in lstFilesDCM:\n",
    "    for index, rows in df.iterrows():\n",
    "        j = i.split(\"_\")[13].strip()\n",
    "        j = int(j[1:7])\n",
    "        if j == index:\n",
    "            bg.append(index)\n",
    "print( [item for item, count in collections.Counter(bg).items() if count > 1] )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstFilesDCM = df['Filenames'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstFilesDCM = lstFilesDCM.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Filenames</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Data ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388578</th>\n",
       "      <td>Control</td>\n",
       "      <td>3969</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 9/3969/Reconstructed_DaTSCAN/2013-02-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767696</th>\n",
       "      <td>PD</td>\n",
       "      <td>3307</td>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/3307/Reconstructed_DaTSCAN/2015-11-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913228</th>\n",
       "      <td>PD</td>\n",
       "      <td>4109</td>\n",
       "      <td>71</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/4109/Reconstructed_DaTSCAN/2017-02-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418920</th>\n",
       "      <td>PD</td>\n",
       "      <td>3504</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 9/3504/Reconstructed_DaTSCAN/2013-01-23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418669</th>\n",
       "      <td>PD</td>\n",
       "      <td>3307</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 2/3307/Reconstructed_DaTSCAN/2012-11-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360624</th>\n",
       "      <td>PD</td>\n",
       "      <td>4101</td>\n",
       "      <td>67</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 2/4101/Reconstructed_DaTSCAN/2012-11-14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360615</th>\n",
       "      <td>PD</td>\n",
       "      <td>3633</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 3/3633/Reconstructed_DaTSCAN/2012-11-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342171</th>\n",
       "      <td>PD</td>\n",
       "      <td>3020</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 5/3020/Reconstructed_DaTSCAN/2012-03-27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355210</th>\n",
       "      <td>PD</td>\n",
       "      <td>3473</td>\n",
       "      <td>55</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 3/3473/Reconstructed_DaTSCAN/2012-08-15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342174</th>\n",
       "      <td>PD</td>\n",
       "      <td>3023</td>\n",
       "      <td>71</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 8/3023/Reconstructed_DaTSCAN/2012-05-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358148</th>\n",
       "      <td>PD</td>\n",
       "      <td>3559</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 9/3559/Reconstructed_DaTSCAN/2012-03-15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419553</th>\n",
       "      <td>PD</td>\n",
       "      <td>3128</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 2/3128/Reconstructed_DaTSCAN/2013-09-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419858</th>\n",
       "      <td>PD</td>\n",
       "      <td>3209</td>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 9/3209/Reconstructed_DaTSCAN/2013-07-31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504846</th>\n",
       "      <td>PD</td>\n",
       "      <td>3455</td>\n",
       "      <td>71</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 2/3455/Reconstructed_DaTSCAN/2015-03-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339896</th>\n",
       "      <td>Control</td>\n",
       "      <td>3310</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/3310/Reconstructed_DaTSCAN/2011-12-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418684</th>\n",
       "      <td>PD</td>\n",
       "      <td>3444</td>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI/3444/Reconstructed_DaTSCAN/2013-03-14_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340347</th>\n",
       "      <td>Control</td>\n",
       "      <td>3405</td>\n",
       "      <td>63</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 3/3405/Reconstructed_DaTSCAN/2010-07-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355941</th>\n",
       "      <td>PD</td>\n",
       "      <td>3252</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 9/3252/Reconstructed_DaTSCAN/2011-12-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419855</th>\n",
       "      <td>PD</td>\n",
       "      <td>3162</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 6/3162/Reconstructed_DaTSCAN/2013-09-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419878</th>\n",
       "      <td>PD</td>\n",
       "      <td>3752</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 2/3752/Reconstructed_DaTSCAN/2013-08-28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846856</th>\n",
       "      <td>PD</td>\n",
       "      <td>3128</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI/3128/Reconstructed_DaTSCAN/2016-10-13_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389239</th>\n",
       "      <td>PD</td>\n",
       "      <td>3459</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/3459/Reconstructed_DaTSCAN/2011-08-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388627</th>\n",
       "      <td>Control</td>\n",
       "      <td>4139</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3/4139/Reconstructed_DaTSCAN/2013-03-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767649</th>\n",
       "      <td>PD</td>\n",
       "      <td>3443</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 9/3443/Reconstructed_DaTSCAN/2016-02-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418654</th>\n",
       "      <td>PD</td>\n",
       "      <td>3125</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/3125/Reconstructed_DaTSCAN/2013-07-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504458</th>\n",
       "      <td>PD</td>\n",
       "      <td>3905</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 6/3905/Reconstructed_DaTSCAN/2014-10-22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913182</th>\n",
       "      <td>PD</td>\n",
       "      <td>3664</td>\n",
       "      <td>66</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 5/3664/Reconstructed_DaTSCAN/2017-04-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495007</th>\n",
       "      <td>PD</td>\n",
       "      <td>3832</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 5/3832/Reconstructed_DaTSCAN/2014-11-25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355943</th>\n",
       "      <td>PD</td>\n",
       "      <td>3352</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3/3352/Reconstructed_DaTSCAN/2012-02-15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913194</th>\n",
       "      <td>PD</td>\n",
       "      <td>3186</td>\n",
       "      <td>66</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 7/3186/Reconstructed_DaTSCAN/2017-05-11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337839</th>\n",
       "      <td>Control</td>\n",
       "      <td>3859</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3.5/3859/Reconstructed_DaTSCAN/2011-08-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355243</th>\n",
       "      <td>PD</td>\n",
       "      <td>4027</td>\n",
       "      <td>66</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 7/4027/Reconstructed_DaTSCAN/2012-08-29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419657</th>\n",
       "      <td>PD</td>\n",
       "      <td>3061</td>\n",
       "      <td>55</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 5/3061/Reconstructed_DaTSCAN/2013-04-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355246</th>\n",
       "      <td>Control</td>\n",
       "      <td>4063</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 6/4063/Reconstructed_DaTSCAN/2012-08-30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446108</th>\n",
       "      <td>PD</td>\n",
       "      <td>3119</td>\n",
       "      <td>66</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI/3119/Reconstructed_DaTSCAN/2014-02-27_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388535</th>\n",
       "      <td>Control</td>\n",
       "      <td>3750</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 5/3750/Reconstructed_DaTSCAN/2011-05-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339900</th>\n",
       "      <td>PD</td>\n",
       "      <td>3314</td>\n",
       "      <td>77</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 7/3314/Reconstructed_DaTSCAN/2012-01-11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418485</th>\n",
       "      <td>PD</td>\n",
       "      <td>3434</td>\n",
       "      <td>55</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI/3434/Reconstructed_DaTSCAN/2012-10-12_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418496</th>\n",
       "      <td>PD</td>\n",
       "      <td>3608</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI/3608/Reconstructed_DaTSCAN/2012-06-05_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389241</th>\n",
       "      <td>PD</td>\n",
       "      <td>3471</td>\n",
       "      <td>74</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3.5/3471/Reconstructed_DaTSCAN/2012-02-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343882</th>\n",
       "      <td>PD</td>\n",
       "      <td>4056</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 5/4056/Reconstructed_DaTSCAN/2012-06-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355938</th>\n",
       "      <td>PD</td>\n",
       "      <td>3150</td>\n",
       "      <td>58</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI/3150/Reconstructed_DaTSCAN/2011-11-30_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419280</th>\n",
       "      <td>PD</td>\n",
       "      <td>4026</td>\n",
       "      <td>76</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/4026/Reconstructed_DaTSCAN/2013-09-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419607</th>\n",
       "      <td>PD</td>\n",
       "      <td>4103</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 5/4103/Reconstructed_DaTSCAN/2014-01-10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358124</th>\n",
       "      <td>PD</td>\n",
       "      <td>3415</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 2/3415/Reconstructed_DaTSCAN/2012-04-13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847069</th>\n",
       "      <td>PD</td>\n",
       "      <td>3823</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 9/3823/Reconstructed_DaTSCAN/2016-06-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418705</th>\n",
       "      <td>PD</td>\n",
       "      <td>3815</td>\n",
       "      <td>63</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3.5/3815/Reconstructed_DaTSCAN/2012-11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339040</th>\n",
       "      <td>PD</td>\n",
       "      <td>4012</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 7/4012/Reconstructed_DaTSCAN/2011-11-10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446133</th>\n",
       "      <td>PD</td>\n",
       "      <td>3622</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 8/3622/Reconstructed_DaTSCAN/2014-03-28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418665</th>\n",
       "      <td>PD</td>\n",
       "      <td>3230</td>\n",
       "      <td>71</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3/3230/Reconstructed_DaTSCAN/2013-07-25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341055</th>\n",
       "      <td>Control</td>\n",
       "      <td>3219</td>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 4/3219/Reconstructed_DaTSCAN/2011-10-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449029</th>\n",
       "      <td>PD</td>\n",
       "      <td>3701</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 3/3701/Reconstructed_DaTSCAN/2014-07-16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436079</th>\n",
       "      <td>PD</td>\n",
       "      <td>3914</td>\n",
       "      <td>59</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 8/3914/Reconstructed_DaTSCAN/2014-04-03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337831</th>\n",
       "      <td>PD</td>\n",
       "      <td>3815</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 6/3815/Reconstructed_DaTSCAN/2011-11-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363964</th>\n",
       "      <td>PD</td>\n",
       "      <td>4106</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>./PPMI 2/4106/Reconstructed_DaTSCAN/2012-12-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341020</th>\n",
       "      <td>PD</td>\n",
       "      <td>3154</td>\n",
       "      <td>73</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 4/3154/Reconstructed_DaTSCAN/2011-01-27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340403</th>\n",
       "      <td>PD</td>\n",
       "      <td>3506</td>\n",
       "      <td>67</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI/3506/Reconstructed_DaTSCAN/2011-01-13_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449033</th>\n",
       "      <td>PD</td>\n",
       "      <td>3780</td>\n",
       "      <td>72</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 3.5/3780/Reconstructed_DaTSCAN/2014-06-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504434</th>\n",
       "      <td>PD</td>\n",
       "      <td>3589</td>\n",
       "      <td>77</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 8/3589/Reconstructed_DaTSCAN/2015-02-18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419853</th>\n",
       "      <td>PD</td>\n",
       "      <td>3113</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>./PPMI 8/3113/Reconstructed_DaTSCAN/2013-07-12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Group  Subject  Age Sex  \\\n",
       "Image Data ID                              \n",
       "388578         Control     3969   80   F   \n",
       "767696              PD     3307   70   M   \n",
       "913228              PD     4109   71   M   \n",
       "418920              PD     3504   63   M   \n",
       "418669              PD     3307   67   M   \n",
       "360624              PD     4101   67   F   \n",
       "360615              PD     3633   69   F   \n",
       "342171              PD     3020   74   F   \n",
       "355210              PD     3473   55   F   \n",
       "342174              PD     3023   71   F   \n",
       "358148              PD     3559   39   M   \n",
       "419553              PD     3128   61   F   \n",
       "419858              PD     3209   70   M   \n",
       "504846              PD     3455   71   M   \n",
       "339896         Control     3310   65   M   \n",
       "418684              PD     3444   70   M   \n",
       "340347         Control     3405   63   F   \n",
       "355941              PD     3252   48   F   \n",
       "419855              PD     3162   63   M   \n",
       "419878              PD     3752   54   M   \n",
       "846856              PD     3128   64   F   \n",
       "389239              PD     3459   52   M   \n",
       "388627         Control     4139   81   M   \n",
       "767649              PD     3443   58   M   \n",
       "418654              PD     3125   47   M   \n",
       "504458              PD     3905   74   F   \n",
       "913182              PD     3664   66   F   \n",
       "495007              PD     3832   67   M   \n",
       "355943              PD     3352   53   M   \n",
       "913194              PD     3186   66   F   \n",
       "...                ...      ...  ...  ..   \n",
       "337839         Control     3859   60   M   \n",
       "355243              PD     4027   66   M   \n",
       "419657              PD     3061   55   F   \n",
       "355246         Control     4063   65   M   \n",
       "446108              PD     3119   66   M   \n",
       "388535         Control     3750   53   M   \n",
       "339900              PD     3314   77   F   \n",
       "418485              PD     3434   55   M   \n",
       "418496              PD     3608   47   M   \n",
       "389241              PD     3471   74   M   \n",
       "343882              PD     4056   64   M   \n",
       "355938              PD     3150   58   F   \n",
       "419280              PD     4026   76   M   \n",
       "419607              PD     4103   60   M   \n",
       "358124              PD     3415   63   M   \n",
       "847069              PD     3823   61   M   \n",
       "418705              PD     3815   63   M   \n",
       "339040              PD     4012   51   F   \n",
       "446133              PD     3622   64   M   \n",
       "418665              PD     3230   71   M   \n",
       "341055         Control     3219   70   M   \n",
       "449029              PD     3701   49   M   \n",
       "436079              PD     3914   59   M   \n",
       "337831              PD     3815   62   M   \n",
       "363964              PD     4106   72   M   \n",
       "341020              PD     3154   73   F   \n",
       "340403              PD     3506   67   F   \n",
       "449033              PD     3780   72   F   \n",
       "504434              PD     3589   77   F   \n",
       "419853              PD     3113   61   F   \n",
       "\n",
       "                                                       Filenames  \n",
       "Image Data ID                                                     \n",
       "388578         ./PPMI 9/3969/Reconstructed_DaTSCAN/2013-02-20...  \n",
       "767696         ./PPMI 4/3307/Reconstructed_DaTSCAN/2015-11-05...  \n",
       "913228         ./PPMI 4/4109/Reconstructed_DaTSCAN/2017-02-24...  \n",
       "418920         ./PPMI 9/3504/Reconstructed_DaTSCAN/2013-01-23...  \n",
       "418669         ./PPMI 2/3307/Reconstructed_DaTSCAN/2012-11-07...  \n",
       "360624         ./PPMI 2/4101/Reconstructed_DaTSCAN/2012-11-14...  \n",
       "360615         ./PPMI 3/3633/Reconstructed_DaTSCAN/2012-11-01...  \n",
       "342171         ./PPMI 5/3020/Reconstructed_DaTSCAN/2012-03-27...  \n",
       "355210         ./PPMI 3/3473/Reconstructed_DaTSCAN/2012-08-15...  \n",
       "342174         ./PPMI 8/3023/Reconstructed_DaTSCAN/2012-05-01...  \n",
       "358148         ./PPMI 9/3559/Reconstructed_DaTSCAN/2012-03-15...  \n",
       "419553         ./PPMI 2/3128/Reconstructed_DaTSCAN/2013-09-18...  \n",
       "419858         ./PPMI 9/3209/Reconstructed_DaTSCAN/2013-07-31...  \n",
       "504846         ./PPMI 2/3455/Reconstructed_DaTSCAN/2015-03-19...  \n",
       "339896         ./PPMI 4/3310/Reconstructed_DaTSCAN/2011-12-08...  \n",
       "418684         ./PPMI/3444/Reconstructed_DaTSCAN/2013-03-14_1...  \n",
       "340347         ./PPMI 3/3405/Reconstructed_DaTSCAN/2010-07-08...  \n",
       "355941         ./PPMI 9/3252/Reconstructed_DaTSCAN/2011-12-21...  \n",
       "419855         ./PPMI 6/3162/Reconstructed_DaTSCAN/2013-09-24...  \n",
       "419878         ./PPMI 2/3752/Reconstructed_DaTSCAN/2013-08-28...  \n",
       "846856         ./PPMI/3128/Reconstructed_DaTSCAN/2016-10-13_1...  \n",
       "389239         ./PPMI 4/3459/Reconstructed_DaTSCAN/2011-08-18...  \n",
       "388627         ./PPMI 3/4139/Reconstructed_DaTSCAN/2013-03-19...  \n",
       "767649         ./PPMI 9/3443/Reconstructed_DaTSCAN/2016-02-24...  \n",
       "418654         ./PPMI 4/3125/Reconstructed_DaTSCAN/2013-07-02...  \n",
       "504458         ./PPMI 6/3905/Reconstructed_DaTSCAN/2014-10-22...  \n",
       "913182         ./PPMI 5/3664/Reconstructed_DaTSCAN/2017-04-18...  \n",
       "495007         ./PPMI 5/3832/Reconstructed_DaTSCAN/2014-11-25...  \n",
       "355943         ./PPMI 3/3352/Reconstructed_DaTSCAN/2012-02-15...  \n",
       "913194         ./PPMI 7/3186/Reconstructed_DaTSCAN/2017-05-11...  \n",
       "...                                                          ...  \n",
       "337839         ./PPMI 3.5/3859/Reconstructed_DaTSCAN/2011-08-...  \n",
       "355243         ./PPMI 7/4027/Reconstructed_DaTSCAN/2012-08-29...  \n",
       "419657         ./PPMI 5/3061/Reconstructed_DaTSCAN/2013-04-19...  \n",
       "355246         ./PPMI 6/4063/Reconstructed_DaTSCAN/2012-08-30...  \n",
       "446108         ./PPMI/3119/Reconstructed_DaTSCAN/2014-02-27_1...  \n",
       "388535         ./PPMI 5/3750/Reconstructed_DaTSCAN/2011-05-18...  \n",
       "339900         ./PPMI 7/3314/Reconstructed_DaTSCAN/2012-01-11...  \n",
       "418485         ./PPMI/3434/Reconstructed_DaTSCAN/2012-10-12_1...  \n",
       "418496         ./PPMI/3608/Reconstructed_DaTSCAN/2012-06-05_1...  \n",
       "389241         ./PPMI 3.5/3471/Reconstructed_DaTSCAN/2012-02-...  \n",
       "343882         ./PPMI 5/4056/Reconstructed_DaTSCAN/2012-06-21...  \n",
       "355938         ./PPMI/3150/Reconstructed_DaTSCAN/2011-11-30_1...  \n",
       "419280         ./PPMI 4/4026/Reconstructed_DaTSCAN/2013-09-18...  \n",
       "419607         ./PPMI 5/4103/Reconstructed_DaTSCAN/2014-01-10...  \n",
       "358124         ./PPMI 2/3415/Reconstructed_DaTSCAN/2012-04-13...  \n",
       "847069         ./PPMI 9/3823/Reconstructed_DaTSCAN/2016-06-07...  \n",
       "418705         ./PPMI 3.5/3815/Reconstructed_DaTSCAN/2012-11-...  \n",
       "339040         ./PPMI 7/4012/Reconstructed_DaTSCAN/2011-11-10...  \n",
       "446133         ./PPMI 8/3622/Reconstructed_DaTSCAN/2014-03-28...  \n",
       "418665         ./PPMI 3/3230/Reconstructed_DaTSCAN/2013-07-25...  \n",
       "341055         ./PPMI 4/3219/Reconstructed_DaTSCAN/2011-10-12...  \n",
       "449029         ./PPMI 3/3701/Reconstructed_DaTSCAN/2014-07-16...  \n",
       "436079         ./PPMI 8/3914/Reconstructed_DaTSCAN/2014-04-03...  \n",
       "337831         ./PPMI 6/3815/Reconstructed_DaTSCAN/2011-11-08...  \n",
       "363964         ./PPMI 2/4106/Reconstructed_DaTSCAN/2012-12-21...  \n",
       "341020         ./PPMI 4/3154/Reconstructed_DaTSCAN/2011-01-27...  \n",
       "340403         ./PPMI/3506/Reconstructed_DaTSCAN/2011-01-13_1...  \n",
       "449033         ./PPMI 3.5/3780/Reconstructed_DaTSCAN/2014-06-...  \n",
       "504434         ./PPMI 8/3589/Reconstructed_DaTSCAN/2015-02-18...  \n",
       "419853         ./PPMI 8/3113/Reconstructed_DaTSCAN/2013-07-12...  \n",
       "\n",
       "[314 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=0.2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = pd.read_csv('comandfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Filenames</th>\n",
       "      <th>TOTAL3</th>\n",
       "      <th>1YR</th>\n",
       "      <th>2YR</th>\n",
       "      <th>3YR</th>\n",
       "      <th>TOTAL3.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688484</td>\n",
       "      <td>PD</td>\n",
       "      <td>./PPMI 5/3108/Reconstructed_DaTSCAN/2015-05-07...</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>18.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>446117</td>\n",
       "      <td>PD</td>\n",
       "      <td>./PPMI/3308/Reconstructed_DaTSCAN/2014-02-12_1...</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>446109</td>\n",
       "      <td>PD</td>\n",
       "      <td>./PPMI 9/3173/Reconstructed_DaTSCAN/2014-03-19...</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>30.50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341084</td>\n",
       "      <td>PD</td>\n",
       "      <td>./PPMI 8/3951/Reconstructed_DaTSCAN/2011-09-28...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363942</td>\n",
       "      <td>PD</td>\n",
       "      <td>./PPMI/3027/Reconstructed_DaTSCAN/2012-11-28_1...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>22.25</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Data ID Group                                          Filenames  \\\n",
       "0         688484    PD  ./PPMI 5/3108/Reconstructed_DaTSCAN/2015-05-07...   \n",
       "1         446117    PD  ./PPMI/3308/Reconstructed_DaTSCAN/2014-02-12_1...   \n",
       "2         446109    PD  ./PPMI 9/3173/Reconstructed_DaTSCAN/2014-03-19...   \n",
       "3         341084    PD  ./PPMI 8/3951/Reconstructed_DaTSCAN/2011-09-28...   \n",
       "4         363942    PD  ./PPMI/3027/Reconstructed_DaTSCAN/2012-11-28_1...   \n",
       "\n",
       "      TOTAL3    1YR   2YR   3YR   TOTAL3.1  \n",
       "0  10.500000  18.00  25.0   NaN  10.500000  \n",
       "1  19.666667  25.00  20.5  27.0  19.666667  \n",
       "2  24.500000  30.50  38.0  49.0  24.500000  \n",
       "3  14.000000  17.75  18.0  10.5  14.000000  \n",
       "4  26.000000  22.25  22.0  17.5  26.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_df = up[['Image Data ID','TOTAL3','1YR','2YR','3YR','TOTAL3']].set_index('Image Data ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4 = df.join(up_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4 = df1to4.dropna(axis=0,subset=(['1YR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4.to_csv('comandfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4 = pd.read_csv('comandfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4 = df1to4[~df1to4.Group.str.contains('Control')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4 = df1to4[~df1to4.TOTAL3.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       False\n",
       "Image Data ID    False\n",
       "Group            False\n",
       "Subject          False\n",
       "Age              False\n",
       "Sex              False\n",
       "Filenames        False\n",
       "TOTAL3           False\n",
       "1YR              False\n",
       "2YR              False\n",
       "3YR              False\n",
       "TOTAL3.1         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1to4.any().isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4.loc[df1to4['Sex']=='F', 'Sex']=0\n",
    "df1to4.loc[df1to4['Sex']=='M', 'Sex']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = (df1to4['1YR'].values - df1to4['TOTAL3'].values)\n",
    "progress = []\n",
    "\n",
    "for i in pro:\n",
    "    if i > 2 : progress.append('1')\n",
    "    elif i < (-2) : progress.append('0')\n",
    "    else : progress.append('0')\n",
    "df1to4['Progress'] = progress\n",
    "df1to4['pro'] = pro\n",
    "del(pro,progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale3 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "print(scale3.fit(df1to4['TOTAL3'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1to4['3scale'] = scale3.transform(df1to4['TOTAL3'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(scale3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tmp, X_test_tmp, param_train_tmp, param_test_tmp, y_train_tmp, y_test_tmp = train_test_split(df1to4, df1to4[['Sex','Age','3scale']], df1to4['Progress'], test_size=0.2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tmp, X_val_tmp, param_train_tmp, param_val_tmp, y_train_tmp, y_val_tmp = train_test_split(X_train_tmp, param_train_tmp, y_train_tmp, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstFilesDCM_train = []  # create an empty list\n",
    "lstFilesDCM_test = []\n",
    "lstFilesDCM_val = []\n",
    "lstFilesDCM_train = X_train_tmp['Filenames'].values\n",
    "lstFilesDCM_train = lstFilesDCM_train.tolist()\n",
    "lstFilesDCM_test = X_test_tmp['Filenames'].values\n",
    "lstFilesDCM_test = lstFilesDCM_test.tolist()\n",
    "lstFilesDCM_val = X_val_tmp['Filenames'].values\n",
    "lstFilesDCM_val = lstFilesDCM_val.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For NORMAL Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 21, 109, 91)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through all the DICOM files\n",
    "image_array_train =[]\n",
    "\n",
    "for filenameDCM in lstFilesDCM_train:\n",
    "    ds = pydicom.read_file(str(SPECTPATH / filenameDCM))\n",
    "    ds_3d = ds.pixel_array[30]\n",
    "    for i in range(31,51):\n",
    "        ds_3d = np.dstack((ds_3d,ds.pixel_array[i]))\n",
    "\n",
    "    image_array_train.append(ds_3d)\n",
    "\n",
    "image_array_train = np.asarray(image_array_train)\n",
    "image_array_train = image_array_train.transpose(0,3,1,2)\n",
    "image_array_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_train= image_array_train.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_train -= image_array_train.min()\n",
    "image_array_train /= (image_array_train.max()-image_array_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 21, 109, 91)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 21, 109, 91)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through all the DICOM files\n",
    "image_array_val =[]\n",
    "\n",
    "for filenameDCM in lstFilesDCM_val:\n",
    "    ds = pydicom.read_file(str(SPECTPATH / filenameDCM))\n",
    "    ds_3d = ds.pixel_array[30]\n",
    "    for i in range(31,51):\n",
    "        ds_3d = np.dstack((ds_3d,ds.pixel_array[i]))\n",
    "\n",
    "    image_array_val.append(ds_3d)\n",
    "\n",
    "image_array_val = np.asarray(image_array_val, dtype='float64')\n",
    "image_array_val = image_array_val.transpose(0,3,1,2)\n",
    "image_array_val -= image_array_val.min()\n",
    "image_array_val /= (image_array_val.max()-image_array_val.min())\n",
    "image_array_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 21, 109, 91)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through all the DICOM files\n",
    "image_array_test =[]\n",
    "\n",
    "for filenameDCM in lstFilesDCM_test:\n",
    "    ds = pydicom.read_file(str(SPECTPATH / filenameDCM))\n",
    "    ds_3d = ds.pixel_array[30]\n",
    "    for i in range(31,51):\n",
    "        ds_3d = np.dstack((ds_3d,ds.pixel_array[i]))\n",
    "\n",
    "    image_array_test.append(ds_3d)\n",
    "\n",
    "image_array_test = np.asarray(image_array_test, dtype='float64')\n",
    "image_array_val = image_array_val.transpose(0,3,1,2)\n",
    "image_array_test -= image_array_test.min()\n",
    "image_array_test /= (image_array_test.max()-image_array_test.min())\n",
    "image_array_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./PPMI5/3023/Reconstructed_DaTSCAN/2014-08-28_14_40_25.0/S237562/PPMI_3023_NM_Reconstructed_DaTSCAN_Br_20150112152112798_1_S237562_I468262.dcm',\n",
       " './PPMI4/3118/Reconstructed_DaTSCAN/2014-02-20_14_02_11.0/S231150/PPMI_3118_NM_Reconstructed_DaTSCAN_Br_20141006104513369_1_S231150_I446107.dcm',\n",
       " './PPMI3.5/3054/Reconstructed_DaTSCAN/2014-12-17_14_37_14.0/S561082/PPMI_3054_NM_Reconstructed_DaTSCAN_Br_20170503135055345_1_S561082_I846852.dcm',\n",
       " './PPMI/3588/Reconstructed_DaTSCAN/2014-10-07_12_10_13.0/S244219/PPMI_3588_NM_Reconstructed_DaTSCAN_Br_20150807124645849_1_S244219_I504433.dcm',\n",
       " './PPMI7/3621/Reconstructed_DaTSCAN/2013-03-01_14_20_10.0/S202934/PPMI_3621_NM_Reconstructed_DaTSCAN_Br_20140403144458594_1_S202934_I418693.dcm']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check matched data-result by Image ID number\n",
    "lstFilesDCM_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Filenames</th>\n",
       "      <th>TOTAL3</th>\n",
       "      <th>1YR</th>\n",
       "      <th>2YR</th>\n",
       "      <th>3YR</th>\n",
       "      <th>TOTAL3.1</th>\n",
       "      <th>Progress</th>\n",
       "      <th>pro</th>\n",
       "      <th>3scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1103</td>\n",
       "      <td>468262</td>\n",
       "      <td>PD</td>\n",
       "      <td>3023</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>./PPMI5/3023/Reconstructed_DaTSCAN/2014-08-28_...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>446107</td>\n",
       "      <td>PD</td>\n",
       "      <td>3118</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>./PPMI4/3118/Reconstructed_DaTSCAN/2014-02-20_...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.264901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>330</td>\n",
       "      <td>846852</td>\n",
       "      <td>PD</td>\n",
       "      <td>3054</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>./PPMI3.5/3054/Reconstructed_DaTSCAN/2014-12-1...</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.326711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>504433</td>\n",
       "      <td>PD</td>\n",
       "      <td>3588</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>./PPMI/3588/Reconstructed_DaTSCAN/2014-10-07_1...</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>46.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.496689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>875</td>\n",
       "      <td>418693</td>\n",
       "      <td>PD</td>\n",
       "      <td>3621</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>./PPMI7/3621/Reconstructed_DaTSCAN/2013-03-01_...</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>0.194260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Image Data ID Group  Subject  Age  Sex  \\\n",
       "1103        1103         468262    PD     3023   73    0   \n",
       "198          198         446107    PD     3118   62    1   \n",
       "330          330         846852    PD     3054   78    1   \n",
       "833          833         504433    PD     3588   51    0   \n",
       "875          875         418693    PD     3621   55    0   \n",
       "\n",
       "                                              Filenames     TOTAL3   1YR  \\\n",
       "1103  ./PPMI5/3023/Reconstructed_DaTSCAN/2014-08-28_...  33.000000  34.0   \n",
       "198   ./PPMI4/3118/Reconstructed_DaTSCAN/2014-02-20_...  22.000000  21.5   \n",
       "330   ./PPMI3.5/3054/Reconstructed_DaTSCAN/2014-12-1...  26.666667  31.0   \n",
       "833   ./PPMI/3588/Reconstructed_DaTSCAN/2014-10-07_1...  39.500000  46.5   \n",
       "875   ./PPMI7/3621/Reconstructed_DaTSCAN/2013-03-01_...  16.666667  14.0   \n",
       "\n",
       "       2YR   3YR   TOTAL3.1 Progress       pro    3scale  \n",
       "1103  38.0   NaN  33.000000        0  1.000000  0.410596  \n",
       "198   12.5  44.0  22.000000        0 -0.500000  0.264901  \n",
       "330   51.0  44.0  26.666667        1  4.333333  0.326711  \n",
       "833   46.0  42.0  39.500000        1  7.000000  0.496689  \n",
       "875   17.0   NaN  16.666667        0 -2.666667  0.194260  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tmp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train_tmp.values)\n",
    "y_train = y_train.astype('int64')\n",
    "y_val = np.asarray(y_val_tmp.values)\n",
    "y_val = y_val.astype('int64')\n",
    "y_test = np.asarray(y_test_tmp.values)\n",
    "y_test = y_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((685,), (294,), (245,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_val.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_train = param_train_tmp.values\n",
    "params = []\n",
    "for i in param_train:\n",
    "    stack = []\n",
    "    stack.append(i)\n",
    "    stack = stack*10\n",
    "    params.append(stack)\n",
    "param_train = np.asarray(params)\n",
    "del(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_val = param_val_tmp.values\n",
    "params = []\n",
    "for i in param_val:\n",
    "    stack = []\n",
    "    stack.append(i)\n",
    "    stack = stack*10\n",
    "    params.append(stack)\n",
    "param_val = np.asarray(params)\n",
    "del(params)\n",
    "\n",
    "param_test = param_test_tmp.values\n",
    "params = []\n",
    "for i in param_test:\n",
    "    stack = []\n",
    "    stack.append(i)\n",
    "    stack = stack*10\n",
    "    params.append(stack)\n",
    "param_test = np.asarray(params)\n",
    "del(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 10, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_train = torch.from_numpy(param_train)\n",
    "param_test = torch.from_numpy(param_test)\n",
    "param_val = torch.from_numpy(param_val)\n",
    "image_array_train = torch.from_numpy(image_array_train)\n",
    "image_array_test = torch.from_numpy(image_array_test)\n",
    "image_array_val = torch.from_numpy(image_array_val)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.utils.data.DataLoader(image_array_train, batch_size=4)\n",
    "param_train = torch.utils.data.DataLoader(param_train, batch_size=4)\n",
    "y_train = torch.utils.data.DataLoader(y_train, batch_size=4)\n",
    "X_val = torch.utils.data.DataLoader(image_array_val, batch_size=4)\n",
    "param_val = torch.utils.data.DataLoader(param_val, batch_size=4)\n",
    "y_val = torch.utils.data.DataLoader(y_val, batch_size=4)\n",
    "X_test = torch.utils.data.DataLoader(image_array_test, batch_size=4)\n",
    "param_test = torch.utils.data.DataLoader(param_test, batch_size=4)\n",
    "y_test = torch.utils.data.DataLoader(y_test, batch_size=4)\n",
    "\n",
    "del(image_array_train,image_array_val,image_array_test)\n",
    "del(X_train_tmp,X_val_tmp,X_test_tmp,y_train_tmp,y_val_tmp,y_test_tmp,param_train_tmp,param_val_tmp,param_test_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks//2),\n",
    "        nn.BatchNorm3d(nf, momentum=0.01),\n",
    "        nn.LeakyReLU(negative_slope=0.1, inplace=False))\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, ni):\n",
    "        super().__init__()\n",
    "        self.conv1=conv_layer(ni, ni//2, ks=1)\n",
    "        self.conv2=conv_layer(ni//2, ni, ks=3)\n",
    "        \n",
    "    def forward(self, x): return x.add_(self.conv2(self.conv1(x.clone())))\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    def make_group_layer(self, ch_in, num_blocks, stride=1):\n",
    "        return [conv_layer(ch_in, ch_in*2,stride=stride)\n",
    "               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes, nf=32):\n",
    "        super().__init__()\n",
    "        features = [conv_layer(1, nf, ks=3, stride=1)]\n",
    "        for i,nb in enumerate(num_blocks):\n",
    "            features += self.make_group_layer(nf, nb, stride=2-(i==1))\n",
    "            nf *= 2                        \n",
    "        features += [nn.AdaptiveAvgPool3d((2,4,4)), Flatten()]        \n",
    "        self.features = nn.Sequential(*features)\n",
    "        fc1 = [nn.Linear(16414, 320), nn.LeakyReLU(negative_slope=0.1, inplace=False)]\n",
    "        self.fc1 = nn.Sequential(*fc1)\n",
    "        self.layers = nn.Sequential(nn.Linear(320,1))\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.features(x)\n",
    "        x = torch.cat((x,y[:,:,0],y[:,:,1],y[:,:,2]),1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, p=0.2, training=self.training)\n",
    "        #return F.log_softmax(self.layers(x), dim=-1)\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (4): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (5): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (7): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (8): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (9): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (10): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (12): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (13): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (14): ResLayer(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (15): AdaptiveAvgPool3d(output_size=(2, 4, 4))\n",
       "    (16): Flatten()\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=16414, out_features=320, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Darknet([1,2,4,3], num_classes=1, nf=32)\n",
    "m.double()\n",
    "#m = nn.DataParallel(m, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "m.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(m.parameters(), lr = 1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "losslog=[]\n",
    "vallog=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(niter):\n",
    "    for epoch in trange(niter):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0        \n",
    "\n",
    "        m.train(True)\n",
    "        scheduler.step()\n",
    "        with tqdm(total=len(X_train)) as pbar:\n",
    "            for i, (x, p, y) in enumerate(zip(X_train,param_train,y_train)):\n",
    "                x,p,y = x.to(device), p.to(device),y.to(device)\n",
    "                #i += 1\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = m(x,p)\n",
    "                loss = criterion(outputs,y.double().unsqueeze(1))\n",
    "                \n",
    "                loss.backward()\n",
    "                for param in optimizer.param_groups[0]['params']:\n",
    "                    param.data = param.data.add(-0.0001 * optimizer.param_groups[0]['lr'], param.data)\n",
    "                optimizer.step()\n",
    "                pbar.update()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % 20 == 19:    # print every 0 mini-batches\n",
    "                    print('[%d, %5d]  Train BCELogitsLoss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 20))\n",
    "                    losslog.append(running_loss/20)\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            #Eval\n",
    "        m.eval()\n",
    "        with tqdm(total=len(X_val)) as pbar:\n",
    "            with torch.no_grad():\n",
    "                truth = []\n",
    "                predicted =[]\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for i, ( x, p, y) in enumerate(zip(X_val,param_val,y_val)):\n",
    "                    x,p,y = x.to(device), p.to(device),y.to(device)\n",
    "\n",
    "                    # forward + backward + optimize\n",
    "                    outputs = m(x,p)\n",
    "                    pred = (F.sigmoid(outputs))\n",
    "                    corr=[]\n",
    "                    for i in pred:\n",
    "                        if i >= 0.68: corr.append(1)\n",
    "                        else: corr.append(0)\n",
    "                    total += y.size(0)\n",
    "                    correct += (corr == y.cpu().numpy()).sum()\n",
    "                    predicted.append(pred)\n",
    "                    truth.append(y)\n",
    "                    pbar.update()\n",
    "\n",
    "                valloss = loss.item()\n",
    "                vallog.append(valloss)\n",
    "                print(f'BCELogitsLoss: {valloss}')\n",
    "                print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))\n",
    "            \n",
    "    print('Finished Training')\n",
    "    return losslog,vallog,truth,predicted    loss = criterion(outputs,y.double().unsqueeze(1))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20/172 [00:46<05:59,  2.36s/it][1,    20]  Train BCELogitsLoss: 0.690\n",
      " 23%|██▎       | 40/172 [01:33<05:11,  2.36s/it][1,    40]  Train BCELogitsLoss: 0.722\n",
      " 35%|███▍      | 60/172 [02:21<04:25,  2.37s/it][1,    60]  Train BCELogitsLoss: 0.703\n",
      " 47%|████▋     | 80/172 [03:08<03:37,  2.36s/it][1,    80]  Train BCELogitsLoss: 0.655\n",
      " 58%|█████▊    | 100/172 [03:55<02:50,  2.37s/it][1,   100]  Train BCELogitsLoss: 0.740\n",
      " 70%|██████▉   | 120/172 [04:43<02:03,  2.37s/it][1,   120]  Train BCELogitsLoss: 0.705\n",
      " 81%|████████▏ | 140/172 [05:30<01:15,  2.37s/it][1,   140]  Train BCELogitsLoss: 0.696\n",
      " 93%|█████████▎| 160/172 [06:18<00:28,  2.37s/it][1,   160]  Train BCELogitsLoss: 0.717\n",
      "100%|██████████| 172/172 [06:45<00:00,  1.93s/it]\n",
      "100%|██████████| 74/74 [00:50<00:00,  1.71it/s]BCELogitsLoss: 0.7280747258520811\n",
      "Accuracy of the network on the val images: 54 %\n",
      "\n",
      " 12%|█▏        | 20/172 [00:46<05:59,  2.36s/it][2,    20]  Train BCELogitsLoss: 0.684\n",
      " 23%|██▎       | 40/172 [01:33<05:12,  2.36s/it][2,    40]  Train BCELogitsLoss: 0.702\n",
      " 35%|███▍      | 60/172 [02:21<04:25,  2.37s/it][2,    60]  Train BCELogitsLoss: 0.696\n",
      " 47%|████▋     | 80/172 [03:08<03:37,  2.37s/it][2,    80]  Train BCELogitsLoss: 0.665\n",
      " 58%|█████▊    | 100/172 [03:56<02:50,  2.37s/it][2,   100]  Train BCELogitsLoss: 0.732\n",
      " 70%|██████▉   | 120/172 [04:43<02:03,  2.37s/it][2,   120]  Train BCELogitsLoss: 0.676\n",
      " 81%|████████▏ | 140/172 [05:30<01:15,  2.37s/it][2,   140]  Train BCELogitsLoss: 0.694\n",
      " 93%|█████████▎| 160/172 [06:18<00:28,  2.36s/it][2,   160]  Train BCELogitsLoss: 0.702\n",
      "100%|██████████| 172/172 [06:45<00:00,  1.93s/it]\n",
      "100%|██████████| 74/74 [00:50<00:00,  1.70it/s]BCELogitsLoss: 0.7119796252634321\n",
      "Accuracy of the network on the val images: 54 %\n",
      "\n",
      "100%|██████████| 2/2 [15:12<00:00, 456.01s/it]Finished Training\n"
     ]
    }
   ],
   "source": [
    "MUL = train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8094666410848532, 0.7621253101425307]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vallog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6899742491367287,\n",
       "  0.7216632823748271,\n",
       "  0.7031199616145714,\n",
       "  0.6551904824257477,\n",
       "  0.7400505342567856,\n",
       "  0.7045912965095784,\n",
       "  0.6957142097621987,\n",
       "  0.716587152393308,\n",
       "  0.6838836016871113,\n",
       "  0.7017663175325224,\n",
       "  0.6961114322213378,\n",
       "  0.664758787050066,\n",
       "  0.7317512962402098,\n",
       "  0.6759753116480365,\n",
       "  0.6937985015888914,\n",
       "  0.7016916941138533],\n",
       " [0.7280747258520811, 0.7119796252634321])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eva():    \n",
    "    m.eval()\n",
    "    with tqdm(total=len(X_val)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            truth = []\n",
    "            predicted =[]\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, ( x, p, y) in enumerate(zip(X_val,param_val,y_val)):\n",
    "                x,p,y = x.to(device), p.to(device),y.to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = m(x,p)\n",
    "                pred = (F.sigmoid(outputs))\n",
    "                corr=[]\n",
    "                for i in pred:\n",
    "                    if i >= 0.52: corr.append(1)\n",
    "                    else: corr.append(0)\n",
    "                total += y.size(0)\n",
    "                correct += (corr == y.cpu().numpy()).sum()\n",
    "                predicted.append(pred)\n",
    "                truth.append(y)\n",
    "                pbar.update()\n",
    "\n",
    "\n",
    "            print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))\n",
    "            \n",
    "    print('Finished Training')\n",
    "    return losslog,vallog,truth,predicted    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:50<00:00,  1.72it/s]Accuracy of the network on the val images: 56 %\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "M = eva()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,50,2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    with torch.no_grad():\n",
    "        n = len(X_test)\n",
    "        ml.eval()\n",
    "        predicted = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with tqdm(total=n) as pbar:\n",
    "            for i, ( x, p, y) in enumerate(zip(X_test,param_test,y_test)):\n",
    "                x,p,y = x.to(device), p.to(device),y.to(device)\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = ml(x,p)\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                total += y.size(0)\n",
    "                correct += (pred == y).sum()\n",
    "    \n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/123 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "TEST = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ml.state_dict(),f'{model_save_path}Predict_progress_3D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Darknet([1,2,4,6,3], num_classes=1, nf=32)\n",
    "ml.double()\n",
    "ml.load_state_dict(torch.load('Predict_pregress_.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ml.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
